{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XExE3pz6vhG"
   },
   "source": [
    "# Dataset exploration\n",
    "\n",
    "In this notebook we will get to know the dataset we will use throughout the tutorial series.\n",
    "\n",
    "The dataset consists of inputs and outputs of a battery degradation model.\n",
    "More specifically, a pseudo-two-dimensional (P2D) model configured to simulate the formation of the solid electrolyte interphase (SEI) in a battery based on the reduction of the solvent near the surface of the negative electrode during charging.\n",
    "\n",
    "The electrolyte considered in the model is a mixture of ethyl carbonate/ethyl methyl carbonate (EC/EMC) with LiPF$_6$ salt. Hence, we assume that main product forming the SEI layer is Li$_2$CO$_3$ and it is formed according to the reaction:\n",
    "\n",
    "$$\n",
    "\\text{S} + 2\\text{Li}^+ + 2e^- \\rightarrow \\text{P}\n",
    "$$\n",
    "\n",
    "where $\\text{S}$ is the solvent species and $\\text{P}$ is the product of the reaction between the solvent ant the Li ions.\n",
    "The growth of the SEI layer is assumed to be in one-dimension and to be controlled by the kinetics of the reaction occurring at the interphase.\n",
    "\n",
    "The inputs and outputs are explored in more detail below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vq7thp398aVr"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6w0L8uY65N3"
   },
   "source": [
    "## Load dataset\n",
    "\n",
    "We can load the dataset directly from the GitHub URL.\n",
    "Alternatively, the dataset can be loaded from a local file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IX4x2ioy6V2C"
   },
   "outputs": [],
   "source": [
    "# load parameter table\n",
    "parameters_path = \"https://raw.githubusercontent.com/BIG-MAP/sensitivity_analysis_tutorial/main/data/p2d_sei_parameters.csv\"\n",
    "# parameters_path = \"./../data/p2d_sei_parameters.csv\"  # local\n",
    "pt = pd.read_csv(parameters_path, index_col=0)\n",
    "pt.unit.replace(np.nan, \"-\", inplace=True)\n",
    "\n",
    "# load dataset\n",
    "dataset_path = \"https://raw.githubusercontent.com/BIG-MAP/sensitivity_analysis_tutorial/main/data/p2d_sei_10k.csv\"\n",
    "# dataset_path = \"./../data/p2d_sei_10k.csv\"  # local\n",
    "df = pd.read_csv(dataset_path, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1PNvGZ9q6_94"
   },
   "source": [
    "## Parameter table\n",
    "\n",
    "Let us first have a look at the parameter table that was used to generate the dataset.\n",
    "The table shows the input parameters of the P2D model along with the selected input ranges (low, high) and nominal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HREV_DtD-1aM"
   },
   "outputs": [],
   "source": [
    "pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FblXBqRe9xcX"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset was generated by sampling the input parameters uniformly at random within the ranges given in the parameter table above.\n",
    "Then the P2D model was used to label each row.\n",
    "The outputs of the P2D model are stored in the last 2 columns of the dataset:\n",
    "\n",
    "    - SEI_thickness(m):   Thickness of the solid electrolyte interphase (SEI).\n",
    "    - Capacity loss (%):  Loss of capacity due to SEI formation.\n",
    "\n",
    "In this analysis we will primarily focus on `SEI_thickness(m)` and optionally on `Capacity loss (%)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9q7o6aDB-3BH"
   },
   "outputs": [],
   "source": [
    "# show dataset statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xM9h7z35_qg0"
   },
   "outputs": [],
   "source": [
    "# show first rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Qt4PfIZAAGX"
   },
   "source": [
    "As you might notice, the first row in the dataset corresponds to the nominal values given in the table. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_ZgmwU-AYkS"
   },
   "source": [
    "## Data visualisation\n",
    "\n",
    "Let us explore the dataset with some visualisations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W8H_W4vd_u-N"
   },
   "outputs": [],
   "source": [
    "# plot histograms\n",
    "_ = df.hist(figsize=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rFZEyCfmAjlk"
   },
   "outputs": [],
   "source": [
    "# plot scatter matrix\n",
    "n = 1000\n",
    "_ = pd.plotting.scatter_matrix(df.iloc[:n], figsize=(20,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vqvDZ2eBl6k"
   },
   "source": [
    "We plot only the first `n = 1000` points in the scatter matrix above as to not crowd the visualisation. Feel free to try and change this number. \n",
    "\n",
    "Since the data is sampled at random, you should see that the data covers the entire input range, as defined in the parameter table, and that the input parameters are not correlated.\n",
    "\n",
    "Perhaps you can also spot some interesting correlations or patterns between the inputs and outputs? It might not be super clear from this figure, but you can try to make a note of the input variables that look interesting to you and follow up on them later in our analysis of this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2i_RRMLER9F"
   },
   "source": [
    "## Outputs\n",
    "\n",
    "Let us have a closer look at the two outputs of interest: `SEI_thickness(m)` and `Capacity loss (%)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "irvqa279AqGT"
   },
   "outputs": [],
   "source": [
    "_ = df[[\"SEI_thickness(m)\", \"Capacity loss (%)\"]].hist(bins=50, figsize=(10, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YavAp8TAFIJi"
   },
   "source": [
    "Both of these outputs are strictly positive and have long tails.\n",
    "In our analysis with machine learning models, it might be useful to instead consider the log transformed outputs to account for these properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yGHkK_KiEpUK"
   },
   "outputs": [],
   "source": [
    "_ = df[[\"SEI_thickness(m)\", \"Capacity loss (%)\"]].transform(np.log).add_prefix(\"log \").hist(bins=50, figsize=(10, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WV0LfwSjGTbh"
   },
   "source": [
    "After applying the log transformation, the outputs are on an unbounded continuous scale, which will be simpler to model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the relationship between the two outputs of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(df[\"SEI_thickness(m)\"], df[\"Capacity loss (%)\"], \".\", alpha=.5)\n",
    "plt.xlabel(\"SEI_thickness (m)\"); plt.ylabel(\"Capacity loss (%)\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like an increase in  `SEI_thickness(m)` correlates with an increase in `Capacity loss (%)`. \n",
    "However, it looks like other factors might also lead to high `Capacity loss (%)`.\n",
    "Perhaps that is something we can also see in the sensitivity analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xt4YX_NgJp4e"
   },
   "source": [
    "## Additional exploration\n",
    "\n",
    "If there is anything else you are curious to know about the dataset, go ahead and create your own plots and statistics below (or wherever you like). \n",
    "Do not forget to save a copy of the notebook if you want to keep your changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0sAWcwQLFU2l"
   },
   "outputs": [],
   "source": [
    "# my additional data exploration\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPij3o7gRl+CYLJWRa6aGts",
   "collapsed_sections": [],
   "name": "Copy of dataset_exploration.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/BIG-MAP/sensitivity_analysis_tutorial/blob/main/notebooks/2_dataset_exploration.ipynb",
     "timestamp": 1642409492380
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
